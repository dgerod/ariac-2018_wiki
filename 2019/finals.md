# ARIAC 2019 Finals

Congratulations to the teams that successfully qualified for the competition through the Qualifiers.

For the ARIAC Finals, qualified teams will submit their system so that it can be run against previously-unseen scenarios.
Teams have already been exposed to all of the challenges that will be present in the Finals scenarios.
A single system must be designed that is agile enough to react to any combination of agility challenges, without knowing which will occur and when.

## What to expect

[The Finals specifications page](https://bitbucket.org/osrf/ariac/wiki/2019/finals_specs) has details on how the competition will be evaluated and what can be expected in the unseen competition scenarios.

## Preparing your system

To ensure that your system can adapt to previously-unseen scenarios, teams should test their system against all released sample trials and the trial configurations used for the Qualifiers.
[The competition configuration file specifications page](https://bitbucket.org/osrf/ariac/wiki/2019/configuration_spec) has details on how teams can create custom trial configuration files to test their system against additional scenarios.

## Submission process

Each team's system will be evaluated automatically against 15 scenarios.
The submission process will be the same as during the qualifiers, as outlined on [the automated evaluation page](https://bitbucket.org/osrf/ariac/wiki/2019/automated_evaluation).
Teams must submit new submission files for the Finals in order to be considered as a participant in the finals.
This is the case even if there were no changes since a team's qualifier submission.
Submissions will be uploaded via the private workspaces, as in the qualifiers.


Teams are also invited to submit an optional one-page synopsis of their approach and its value as an agile robotic system.
This synopsis will be provided to the human judges as part of their review of systems for judging.
[The challenge.gov page](https://challenge.gov/a/buzz/challenge/999/ideas/top) summarizes the way in which automated scoring metrics will be combined with the judges' evaluations.

## Pre-Finals dry-run testing of submissions

Teams will be able to submit their system for testing on the machine used to run the competition for a limited amount of time before the Finals.
Teams' systems will be validated against sample trials, not the trials that will be used in the Finals.
The ARIAC competition team will work with teams to resolve problems related to running their system on that machine.
This will be done on a first come, first served basis.

To have your submission validated:

1. Upload your submission to your NFiles folder just as you did for the qualifier
2. Send an email to ariac@nist.gov with your team name asking for your submission to be validated.
3. You will receive an email when the results of your submission are available.

## Schedule


- Until May 6: Teams test their submission using the mock competition setup on their machine.
- May 6-10, 2019: Dry-run testing and iteration with teams to help resolve issues with their entries.
    - May 10, 2019 @ 4:00pm PDT: Deadline for submission for dry run testing.
- May 12, 2019 @ 11:59pm PDT: Deadline for final submissions from qualified teams, including the optional one-page system synopsis.
- May 13-20, 2019: Perform official competition runs.